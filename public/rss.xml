<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[YP Engineering Website]]></title><description><![CDATA[YP Engineering Website]]></description><link>http://engineering.yp.com</link><image><url>http://engineering.yp.com/img/rss.png</url><title>YP Engineering Website</title><link>http://engineering.yp.com</link></image><generator>NodeJS RSS Module</generator><lastBuildDate>Tue, 05 Mar 2013 17:49:44 GMT</lastBuildDate><atom:link href="http://engineering.yp.com/rss.xml" rel="self" type="application/rss+xml"/><item><title><![CDATA[Application Security Automation]]></title><description><![CDATA[Web application security is a serious problem, and it's not going away.  Almost
every day we see articles on WSJ regarding breaches, including WSJ itself.



There are several high-level problems facing the business world:

1) Higher quality (more secure) products are more expensive

2) Lack of application security engineers

3) Accepting there is a problem that requires resources to be addressed



On a tactical level, common organizational issues with application security
include:

-   **It's ad-hoc**, performed on some web apps, some of the time

-   **Expertise varies**, widely between engineers that perform assessments

-   **No common workflow,** security issues not integrated with developer
    systems and processes

-   **Seeing is believing**, vulnerabilities discovered need to have a
    proof-of-concept; developers need to see the exploit and impact



To address these business and tactical issues we partnered with WhiteHat
Security.  WhiteHat is a SaaS security offering.  They have a team of expert
application security engineers that hammer on our applications every day, just
like BlackHats, with the exception that these security problems are discovered,
verified, and sent to us.  As G.I. Joe says, '*Now you know, and knowing is half
the battle.*' The other half is getting these issues to developers on a fix
roadmap.



**Jira Integration with WhiteHat Sentinel**

Changes and fixes needed from developers are described in JIRA issues or
'tickets'. Since our development groups already have a mature workflow for
prioritizing, delegating, and tracking issues in JIRA, WhiteHat's
vulnerabilities need to be translated in to this format.

Manually interpreting WhiteHat vulnerabilities and creating correlating new
tickets into JIRA tickets is untenable.  WhiteHat's vulnerability data is
extensive and having someone on staff do a daily manual copy-and-paste from one
ticketing system to another is tedious, inaccurate, and slow.  Fortunately
there's a solution to automate the whole lifecycle.

WhiteHat's service includes access to their JIRA plugin.  This plugin is
incorporated in to YP's JIRA, and connects it to WhiteHat Sentinel according to
rules that have been custom-tailored for YP's development teams.  Every hour,
the Jira plugin:



1.  Makes an encrypted and authenticated connection to WhiteHat's API

2.  Polls WhiteHat for 'open issues'

3.  Creates Jira tickets describing the issues and assigns them to the
    developers responsible for that project

4.  Reopens Jira tickets accidentally closed before WhiteHat confirmed they were
    fixed

5.  Polls for issues that WhiteHat has confirmed are fixed.

6.  Closes those tickets in Jira.



The result is a seamless reflection of problems found by WhiteHat into
developers' to-do lists in JIRA.  Issues are fully tracked and synchronized
throughout the full lifecycle of discovery, testing and proof of concept,
prioritization, correction, and verification.  Within moments of a new
vulnerability creeping up, it's already detected, prioritized to be fixed, and
tracked to completion.



-YP Information Security
]]></description><link>/post/sec</link><guid isPermaLink="true">/post/sec</guid><dc:creator><![CDATA[Mikhael and Jim]]></dc:creator><pubDate>Thu, 04 Apr 2013 07:00:00 GMT</pubDate></item><item><title><![CDATA[Javascript Source Analysis]]></title><description><![CDATA[It's important to get an idea of the maintainability and complexity of your codebase.
I am using a great tool called [plato](https://github.com/jsoverson/plato) that doing exatly that. You run it against your js files and it generate a beautiful website that gives you a visual insight about the health of your project.

First, install it

    npm install plato -g

Now run it and give it your project's Javascript files:

    plato -d report-folder *.js

Here is a snapshot of a project I worked on: 

![project before](http://i.imgur.com/ZDrlLzD.png)

The first thing we can see is the maintainability score: 75.27. The maintainability scale is a number between 0 - 100 where the higher, the better. It is measured based on a few parameters - number of distinct paths in a code, number of operators and operands and logical lines of code. For the exact definition check out [JsComplexity.org](http://jscomplexity.org/complexity).

The orange lines represent each file in my project. The shortest the line the easy it is to maintain it. The shortest line in my project is the router.js file (hover on a line will show you it's name and rank). This file has less than 50 points of maintainability.
The generated webpage let's you click on any file where you can see the code base with each function graded by it's complexity and other metrics.

Here is my router.js file:
![router before](http://i.imgur.com/BvEqlHA.png)

The router function got a complexity score of 11. Complexity is measured by the number of paths your code can take. if-else statement for example will add 1 point. If your function is above 10, it's a good idea to refactor it.

Firest, let's look at the code:

    // The server's main routes function
    //
    // Supports the following end-points:
    // POST /push
    // POST /register
    // POST /register.php
    // GET /health
    // GET /health.txt

    function router(config, req, res) {
      if (req.url == '/push') {
        if(req.method.toLowerCase() == 'post') {
          pusher(config, req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      } else if (req.url == '/register') {
        if(req.method.toLowerCase() == 'post') {
          register(config, req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      } else if (req.url == '/register.php') {
        if(req.method.toLowerCase() == 'post') {
          registerLegacy(config, req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      } else if (req.url == '/health') {
        if(req.method.toLowerCase() == 'get') {
          info = health(req.connections);
          res.end(JSON.stringify(info));
        } else {
          res.statusCode = 405;
          res.end();
        }
      } else if (req.url == '/health.txt') {
        if(req.method.toLowerCase() == 'get') {
          checkHealth(req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      } else {
        res.statusCode = 404;
        res.end();
      };
    };

This function have many if-else statements that each can be extracted into it's own function. Let's extract 5 small functions to make it smaller and readable:

    function router(config, req, res) {
      if (req.url == '/push') { 
        pushRoute();
      } else if (req.url == '/register') { 
        registerRoute();
      } else if (req.url == '/register.php') { 
        registerPhpRoute();
      } else if (req.url == '/health') { 
        healthRoute();
      } else if (req.url == '/health.txt') { 
        healthTxtRoute();
      } else {
        res.statusCode = 404;
        res.end();
      }

      function pushRoute() {
        if(req.method.toLowerCase() == 'post') {
          pusher(config,  req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      }

      function registerRoute() {
        if(req.method.toLowerCase() == 'post') {
          register(config, req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      }

      function registerPhpRoute() {
        if(req.method.toLowerCase() == 'post') {
          registerLegacy(config, req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      }

      function healthRoute() {
        if(req.method.toLowerCase() == 'get') {
          info = health(req.connections);
          res.end(JSON.stringify(info));
        } else {
          res.statusCode = 405;
          res.end();
        }
      }

      function healthTxtRoute() {
        if(req.method.toLowerCase() == 'get') {
          checkHealth(req, res);
        } else {
          res.statusCode = 405;
          res.end();
        }
      }
    }

**Note**: I am nesting the small functions instead of locating them outside of the router function so I can avoid passing the arguments to each one. Don't you agree that Javascript clojures are awesome?!

Let's generate the report again:

    plato -d report-folder *.js

![project after](http://i.imgur.com/Z8EVEGj.png)

Nice! our project maintainabily score is higher now and the router.js file is ranked above 50.  
Let's drill down to the file-level report:

![router after](http://i.imgur.com/ALoAGbi.png)

After this refactor the complexity of the router function was reduced from 11 to 6, and each of the small function have a complexity of 2 (hover on the blue circle will show that). 

In addition to complexity report, this tool also use [JSHint](http://www.jshint.com/about) which helps in ensuring you use good practices of the Javascript language.

Now you can automate it by adding it to your make file and running it with `make report`

<pre>
    report: 
      plato -d report-folder *.js
</pre>

The last step can be to add it to your Continuous Integration server.
]]></description><link>/post/js-source-analysis</link><guid isPermaLink="true">/post/js-source-analysis</guid><dc:creator><![CDATA[Oren]]></dc:creator><pubDate>Tue, 19 Feb 2013 08:00:00 GMT</pubDate></item><item><title><![CDATA[Glendale's Best Eateries]]></title><description><![CDATA[Most of the engineering teams are located in Glendale, CA.
Glendale (Eastern end of the San Fernando Valley) is the 3rd largest city in Los Angeles with 191,719 people.
Also a home for the largest Armenian population.  (1 in 4 are Armenian!)
With a large city comes big demands for great places to "get your grub on".

Here are my picks for the best eateries in town:

## Porto's Bakery  
315 N Brand Blvd, Glendale, CA 91203 
Price Range:  $

![Imgur](http://i.imgur.com/tJ7qd.jpg)
![Imgur](http://i.imgur.com/CjArq.jpg)

This place is no itty bitty bakery!  20,000 square feet of mouth watering desserts, sandwiches, soups, coffee!  You can find Cuban, French, Danish, and Italian delicacies here at Porto's Bakery.  A family run business since the 1990's, this gem brings in thousands of people from all over Southern California and has now grown into 2 other cities.  You are missing out if you haven't given this place a try.  Go support a local family business.

## Raffi's Place Restaurant  
211 E Broadway, Glendale, CA 91205 
Price Range:  $$

![Imgur](http://i.imgur.com/e3PAG.jpg)
![Imgur](http://i.imgur.com/bvIKa.jpg)
![Imgur](http://i.imgur.com/VFyMs.jpg)

Raffi's place is a unique place the best Persian food in the valley.  Kabob Bargh (fillet Mignon), Kabob Koobideh (ground meat), Mast o moosir(yogurt and shallots), Basmati rice, Baklava, Soltani kabob(fillet Mignon and ground beef), hummus..... need I say more???  This place is packed every night but it is worth the wait!  

## Sushi Nishiya
1712 Victory Blvd Glendale, CA 91201
Price Range:  $$$$

![Imgur](http://i.imgur.com/kgxPz.jpg)
![Imgur](http://i.imgur.com/Oy26t.jpg)

I have always been a fan of Japanese food and I must say that this is one of the best.  So who cares if this place is ridiculously expensive right?  If you want FRESH fish this is the place to go in the valley.  This place does not match the price tag to the rent they pay as it is located in a run down strip mall but we all know that sometimes these kind of places are better than the fancy schmancy restaurants.  Omakase in Japanese is a phrase they use to say "I'll leave it to you".  This restaurant is unique in that everything is "omakase" and the sushi chef will only serve you the freshest fish of the day. Some people compare Sushi Nishiya to authentic sushi restaurants in Japan. Listen to me and try it out, you will not regret it.  

Happy eating everyone!
    

]]></description><link>/post/restaurants</link><guid isPermaLink="true">/post/restaurants</guid><dc:creator><![CDATA[Xiangning]]></dc:creator><pubDate>Thu, 14 Feb 2013 08:00:00 GMT</pubDate></item><item><title><![CDATA[Turn that "Grunt" upside down!]]></title><description><![CDATA[![grunt](http://a2.ec-images.myspacecdn.com/images02/56/4931bf18944e44d4b4908fdb0decebac/l.jpg)

## What is Grunt?
Grunt is a build tool for JavaScript projects. It automate all the annoying tasks so you don't have to think about them.
a few common examples are linting, assets minification, compiling stuff (coffeescript, stylus, etc) and running your tests on code change.  
It's open source and available on github. [This](http://gruntjs.com/) is Grunt's website.

In this blog post I want to show you how to install it and  how to automate a few common tasks.  
Hopefully it will convince you to drop everything you are doing and you'll find yourself adding grunt to your current project.

*note - your can get the complete code sample [here](https://github.com/oren/oren.github.com/tree/master/posts/grunt).*

## Installing Grunt
Grunt is available as an npm module. npm is the package manager for node.js, so you'll need to install node first.  
Go get it [here](http://nodejs.org/) and come back. I am waiting.

Now that you have node, you can use npm to install all kind of fun packages. grunt is one of them: 

    npm install grunt -g

The above command will install grunt globally (that's the reason for the -g) - it will be available for use in all of your projects. Once grunt has been installed, you can type grunt --help at the command line for more information. 

## Lint, concatenate and minimize our JavaScript files
JavaScript is a wild language. you can twist and bend it to your needs but you can easily shoot yourself in the foot.  
Javascript Lint is a tool that checks for common mistake in your codebase. it will be nice to use lint and get errors from all the Javascript files in my project. In addition for lintinting, I want to concatenate the JavaScript files into a single file, and minimize that file.  

create a new folder for your project and add the following structure:

    └── public
        ├── css
        ├── js
        │   └── app.js
        └── styles
            └── app.styl

app.js and app.styl can remain empty. you can also use [my code](https://github.com/oren/oren.github.com/tree/master/posts/grunt).

create `grunt.js` in the root dir of your project. this is grunt's config file.

    module.exports = function(grunt) {
      grunt.initConfig({
        lint: {
          files: ['public/js/app.js']
        },
        jshint: {
          options: {
            curly: true,
            eqeqeq: true,
            immed: true,
            latedef: true,
            newcap: true,
            noarg: true,
            sub: true,
            undef: true,
            boss: true,
            eqnull: true
          }
        },
        concat: {
          dist: {
            src: [
              'public/js/prettify.js',
              'public/js/ga.js',
              'public/js/app.js'
            ],
            dest: 'public/js/production.js'
          }
        },
        min : {
          dist : {
            src : 'public/js/production.js',
            dest : 'public/js/production.min.js'
          }
        }
      });

      grunt.registerTask('default', 'lint concat min');
    };

let's see what happend when you run `grunt`

    grunt

    Running "lint:files" (lint) task
    Lint free.

    Running "stylus:compile" (stylus) task
    File public/css/site.css created.

    Running "cssmin:dist" (cssmin) task
    File 'public/css/production.css' created.
    Uncompressed size: 20097 bytes.
    Compressed size: 3270 bytes gzipped (13445 bytes minified).

    Running "concat:dist" (concat) task
    File "public/js/production.js" created.

    Running "min:dist" (min) task
    File "public/js/production.min.js" created.
    Uncompressed size: 14717 bytes.
    Compressed size: 6257 bytes gzipped (14281 bytes minified).

    Done, without errors.

That's it. all the tasks that are defined in grunt.registerTask will run - lint, concat and min.  
notice that lint, concat and min are all tasks that comes built-in with grunt. There are additional tasks that are not part of the core grunt but avaialable as well. we will look at some of them in the next section.

Now that we got a basic flow working, let's add a few more things.

## Compiling stylus files into css

I like [stylus](http://learnboost.github.com/stylus/). You write very clean css-like files that compile into css.  
Let's add a grunt task that do just that. I want to type `grunt stylus` and all my .style files will compile into .css files.  
add the following to grunt.js:

    stylus: {
      compile : {
        files : {
          'public/css/site.css' : 'public/styles/*.styl'
        }
      }
    },

if you'll try running it with `grunt stylus` you'll see this warning:

    Warning - Task "stylus" not found. Use --force to continue.
    Aborted due to warnings.

what happend? oh, stylus task does not come with grunt. we'll have to add it ourself.

    npm install grunt-contrib --save-dev

and add this line before the last line of grunt.js:

    grunt.loadNpmTasks('grunt-contrib');

and add app.styl file inside public/styles

run `grunt stylus` and hopefully everything is ok now.

now add it to registerTask: 

    grunt.registerTask('default', 'lint stylus concat min');

and run all of them with `grunt`

## Minimize css files

great. now let's add a grunt task to minimize all our css files into one file that will be used in production environment.  
start by adding this key to the grunt.js file:
    
    cssmin : {
      dist : {
        src: [
          'public/css/font-awesome.css',
          'public/css/site.css',
          'public/css/prettify.css'
        ],
        dest: 'public/css/production.css'
      }
    },

cssmin is part of the grunt-css package. install it with npm:

    npm install grunt-css --save-dev

and add this line right next to the other loadNpmTasks line:

    grunt.loadNpmTasks('grunt-css');                                 

and run it with `grunt cssmin`.  
if all is good, add it to registerTask line and run `grunt`

    grunt.registerTask('default', 'lint stylus concat cssmin min');  

## Watch for file changes and do stuff

if everything is working so far, let's add one more thing. grunt can watch for file changes and run whatever tasks we want.  
let's run the lint task whenever we change our JavaScript files and the stylus task when we modify our stylus files:

    watch: {
      stylus: {
        files: ['public/styles/*.styl'],
        tasks: 'stylus'
      },
      lint: {
        files: '<config:lint.files>',
        tasks: 'lint'
      }
    }

now run:

    grunt watch

and edit app.js or app.styl files and notice the watch doing it's job.  

## Summary

Well done, you know how grunt work, how to add tasks to grunt and how to watch for file changes.  
Now go ahead and start using it!

]]></description><link>/post/grunt</link><guid isPermaLink="true">/post/grunt</guid><dc:creator><![CDATA[Oren]]></dc:creator><pubDate>Fri, 11 Jan 2013 08:00:00 GMT</pubDate></item><item><title><![CDATA[Ask the Crowd, Ask Me How!]]></title><description><![CDATA[Imagine an industry buzzword that described millions of human brains thinking in parallel

![image](http://25.media.tumblr.com/QPxunWAveljvzdz7Mtqb4fP8o1_500.jpg)

Microtask crowdsourcing breaks a daunting project into small, simple tasks and distributes them to a "crowd" of anonymous internet citizens. Using [Amazon Mechanical Turk](http://www.mturk.com), and other crowdsourcing platforms YP employees have quietly but steadily developed experience and expertise with a variety of use cases since 2006.  

**Hours of Operation Standardization** - A simple formatting task that would serve as training data for parsing algorithms.  

**Business URL Validation and Closed Business Validation** - Data validation is still labor intensive, and we have used a combination of in house experts and crowdsourced labor with mixed success.  

**Category Relevancy and Search Query Categorization** - Generating training data for Primary Category Designation and Search algorithms.  

**Category Keyword Associations** - Search Engine Marketing to drive relevant traffic.

**Photo Moderation** - Curating user generated content at 1/6 market price!  

**Search Relevancy** - Stacking the YP Search Algorithm up against its biggest competition to expose the weaknesses and strengths of each.  

**Spellchecking** - Identify the edge cases when a small business owner thinks it's cute to misspell their store 'Starz' instead of 'Stars.'

**Query/Geo segmentation** - Training data for a Single Search Box.  

As you can see, our most common use is measuring subtleties in datasets that computer algorithms are unable to detect. Microtasking means that the work is short, simple, and repetitive, but more complex forms of crowdsourcing are beginning to evolve and build their niche. Sites like [99designs](http://www.99designs.com) for logo designs, [uTest](http://www.utest.com) for QA, [TopCoder](http://www.topcoder.com/) for software development, and [Kaggle](http://www.kaggle.com/) for data science are targeting a more qualified workforce and moving crowdsourcing into new territory.  

## Join the Crowd, Be Assimilated or Resist Futily  

![image](http://images.hollywood.com/site/6a00e550f49766883401156fd23f48970b-800wi.jpg)

The crowd may be a model for the future white-collar workforce. IBM Germany has (to some measure of public outcry) leaked the pilot for a radical staffing program called [Liquid](http://knowledge.asb.unsw.edu.au/article.cfm?articleid=1677). Only a small circle of executives will remain in the German offices, and all other employees will work in a freelance capacity through a special crowdsourcing platform. 

The initial public reaction might be one of outrage at another attempt to erode the rights of the working class in the name of cost savings, but an optimistic (and perhaps more enlightened) view could interpret this as a step towards a utopia of worker empowerment. If tech companies expand their use of crowdsourcing the way IBM is starting to, workers gain the freedom to set their own hours and sell their skills in a dynamic marketplace. An ambitious project manager or software developer may work on projects for several different companies at the same time, while someone with a seasonal hobby could take months of the year off and still be confident that work will be available when they return. Remaining prejudices are wiped out, and people will be hired solely on the basis of their qualifications.  

Are these the ramblings of an objectivist lunatic? A future golden age made possible by the internet? Do you see any other benefits, drawbacks or opportunities? Let's hear your thoughts in the comments.
]]></description><link>/post/crowd</link><guid isPermaLink="true">/post/crowd</guid><dc:creator><![CDATA[Daniel]]></dc:creator><pubDate>Wed, 12 Dec 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[Quang Gip is a Yellow Pager!]]></title><description><![CDATA[![quang](http://i.imgur.com/SwDZP.png)

I'm currently working as a software engineer on the search team.  My previous job was a qa engineering and a release engineer, which I managed testing and source code management.  I hope to apply the same experience and contribute at my current job.

Outside of work, I enjoy going to the gym and doing photography in my spare time.  I also post-process my own photos.  I'm not a picky person in general, but I am in my photography because I strive for perfection even though it doesn't exist :)

That's pretty much me in a nutshell.
]]></description><link>/post/quang</link><guid isPermaLink="true">/post/quang</guid><dc:creator><![CDATA[Yellow Pages]]></dc:creator><pubDate>Tue, 11 Dec 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[What does a Product Manager do?]]></title><description><![CDATA[People often ask me "What does a product manager do?". And, someone recently confessed that when I told her I was a Product Manager, she wondered "What does that mean?".

So, let me break it down. A Product Manager (**PM**) is responsible for coming up with the product concept (Ideation), selling the concept (Communication) and ensuring timely launch (Execution) of the product.

![project management](http://i.imgur.com/6kPIt.jpg) **<span style="color:#3366ff">Ideation</span>**  At a minimum, a PM is responsible for the product concept - coming up with the vision or refining an existing idea. He will take a vague idea and turn it into detailed, specific requirements & features. Not only that, he will prioritize these requirements and associate them with real world situations (Use Cases) for when someone or something may interact with the product. These Use Cases have to carry sufficient detail so that they clearly convey the scope and product features. This way smart Engineers can build it into something in real-life. And, the Quality Assurance (QA) folks need to refer to these Use Cases to figure out how to test the product and ensure that it does what its supposed to do.

**<span style="color:#3366ff">Communication</span>**  Its extremely important that a PM gets buy-in from the stakeholders on the product. Nobody wants to do the work unless they are convinced it's worth their while. So, it falls to the PM to identify market opportunity, benefits and ROI (return on investment) if this product were to be created. Then, he will turn all this data into a convincing rationale to create this product.

Equally important, the PM will define KPIs (Key Performance Indicators) for product success and indicate why these are the relevant KPIs. Upon launch (or during an AB test or bucket test), the PM will measure these KPIs to gauge performance. He will report this information to relevant interested parties and define any tweaks necessary to improve the product.

A good PM will not only define the business case but also outline how an end-user will interact with the product - what we call User Experience (UX). To this end, PMs create Wireframes or Storyboards that define the major visual elements of the product and detail the user interaction. If an organization has the luxury of recruiting Product Designers (PD), then PMs work with PDs to create realistic mock-ups (often called Comps) of the look-n-feel of the finished product.

If a product requires training the end-users, then the PM defines training scope, gauges/foresees customer needs and stays actively involved in development, delivery and fine-tuning of relevant documentation and related user experience.

**<span style="color:#3366ff">Execution</span>**  Since the PM identifies the business opportunity & market window, he has effectively defined the product launch time-frame. Someone has to keep the trains running on time, right? A good PM will often play train-conductor along-with a Project Manager (PjM). So, it falls to him to ensure product kick-off happens as planned, offering clarification on product requirements to Engineers and making trade-off decisions on scope vs timeline vs ROI with Engineers and QAs.

During execution, a PM plays the role of roadblock-remover for Engineering and QA, which is similar to the role of Scrum Master in the Scrum Project Management methodology. To this extent, there is an overlap in PM and PjM skills. If a team is pressed for resources, a PM will perform dual PM-PjM roles. This is why it important for a good PM to have solid project management skills. And strong PMs, often have at least a good understanding of PjM skills or possibly prior experience as PjM.

If AB Test/bucket test is being performed before full launch, a PM will define test scope. Subsequently, the PM works hand-in-hand with a Release Manager(RM) & PjM to define launch timelines and KPI measurement frequency.

**<span style="color:#3366ff">In conclusion</span>**, Product Management is a complex role that is very invested in the entire product life-cycle from concept to delivery and maintenance. PMs wear multiple hats, shoulder various responsibilities, must have a facility for observation and speak several 'languages' to identify and communicate what matters most to each group of internal & external stakeholders including customers.

My buddy, Uday S, says "A Product Manager is the CEO of his product". He nailed it.

*This blog post is a reproduction of my original post at [www.curryNcapital.com](http://curryncapital.com/2012/11/20/pmresponsibilities)*

]]></description><link>/post/project-management</link><guid isPermaLink="true">/post/project-management</guid><dc:creator><![CDATA[Gunjan Sharman]]></dc:creator><pubDate>Tue, 20 Nov 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[The Usability Toolbox, Part One: Usability Lab]]></title><description><![CDATA[by Natalie Dunbar | User Experience Design

![dilbert](http://twiki.org/p/pub/Codev/TWikiUsability/reboot.gif)

If you had a way to engage users of your products and services, particularly (and especially) before they launch, and you could observe those users could as they interact with a live or prototype version of whatever you’re building, what would it be worth to you?

If you could engage with those users – we prefer to call them participants – in a lab-like setting as close to a real usage scenario as you can create in a corporate space, have them use and poke at your product and then give you on-the spot-feedback on whether or not they would use what you’ve built and how exactly they would use it, how quickly would you jump in line for a chance like that?

YP is fortunate enough to have space in our offices dedicated to just that purpose: the Usability Lab. As you can imagine, in a building where the demand for conference room is high compared with a somewhat limited supply, the lab is a space coveted by many. Yet, because it is in use on a near-weekly basis, testing everything from consumer-facing features on YP.com and YPmobile, to products and services built for our Advertisers, it is a space that is exclusively dedicated by necessity.

### Usa-what?

The International Standards Organization (ISO) defines Usability, in part, as “…the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context.”
  
That’s a fancy way of saying “If you build it, can they use it? And if they can (are “able to”) will it be used as intended?” 

In garnering that kind of hands-on feedback, stakeholders from across the organization (engineering, product, marketing, etc.) get a first hand look at how our products are solving user problems – or, even more important, how a product actually may create a problem. The best part about the latter scenario is that if you’ve recruited your participants correctly, they will usually articulate how to improve on the pain points they identify, often without prompting.

### Recruiting Participants

Before ever setting foot in the lab, our Usability Specialists are usually contacted by a Product Manager who is either building a new product or feature, or improving on an existing one. After a kick-off meeting and a first look at the product, either as a prototype, in a QA environment, or live in production (and sometimes as wireframes or comps), the Usability Specialist works with the product stakeholder to create the basis for a testing script. 

This “test” is really a set of tasks that you want the participants to complete – and we are quick to tell each participant that there are no right or wrong answers to this “test.” We want their pure, honest and completely unfiltered feedback. We’re not worried about getting our feelings hurt in the process because we want to help our stakeholders build a better – and usable – product.

### Testing, Testing

The real fun begins when you’re actually sitting in the lab, observing participants as they walk through each task. The Usability Specialists’ main job is to listen and to guide – not lead – the participant through a series of tasks to see if they can achieve the end goal that the product was created to achieve. You also want to note how long it takes, and how satisfied (or not) the participants are with what is being tested.

We’re also lucky enough to have an Observation Room where stakeholders can sit opposite a one-way mirror (with the participants knowledge and permission) and watch and listen to what the participants have to say. 

There is nothing like getting a first-hand look at how what you’ve built will be used in near-real world scenarios. It can be a bit painful and maybe even a bit harsh sometimes, but because the participants are representative of the people you’ve built your product or service for, there is no better way to eliminate pain points and solve problems before you launch.

### Next Up

The Usability Toolbox, Part Two: Online Community as an Insight Tool for Product Innovation
]]></description><link>/post/usability</link><guid isPermaLink="true">/post/usability</guid><dc:creator><![CDATA[Natalie Dunbar]]></dc:creator><pubDate>Thu, 15 Nov 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[Node Knockout]]></title><description><![CDATA[<iframe width="560" height="315" src="http://www.youtube.com/embed/5COW63KXEcU" frameborder="0" allowfullscreen></iframe>

163 teams all over the world celebrated Node Knockout 2012 this weekend. Node Knockout is 48 hours of non-stop Node.js hackery.

[Substack](https://github.com/substack), [Dominic](https://github.com/dominictarr), and [Raynos](https://github.com/Raynos) created a browser-based, multi-player adventure game where you can cast spells on any object around you by changing the object's javascript code! For example, you can turn your friend into a monster or a rock if he pisses you off. Click on anything around you to see it's code and start hacking!

Play it! - [http://wizardz.jit.su](http://wizardz.jit.su)   
The code - [https://github.com/substack/wizard-game](https://github.com/substack/wizard-game)  
Node Knockout - [http://nodeknockout.com](http://nodeknockout.com)  

For those of you who want a peek behind the curtain: 
> we use a streaming data replication module, [crdt](https://github.com/dominictarr/crdt), and then connect it up over [mux-demux](https://github.com/dominictarr/mux-demux) (stream multiplexer) and [shoe](https://github.com/substack/shoe). shoe provides a stream api over websockets, mux-demux provides multiple streams over a single stream and crdt provides a data model that can be updated from either end, and is eventually consistent.

I have no better picture to describe my brain now:
![wtf-cat](http://www.thejayfk.com/wp-content/uploads/2011/01/WTF.jpg)

]]></description><link>/post/wizard</link><guid isPermaLink="true">/post/wizard</guid><dc:creator><![CDATA[Oren]]></dc:creator><pubDate>Tue, 13 Nov 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[It's Friday!]]></title><description><![CDATA[How do I know when it's Friday?  When I get looks like this...  
![Friday](http://i.imgur.com/qWJJC.jpg)

Normally during the week, I tend to dress business casual; nothing outlandish or enough to stand out.  The rest of the office doesn't subscribe to my more conservative dress.  The flip-flops, shorts, and bow tie crowd can be pressuring, but I have to have my slacks and dress shirts!  
  
However, it's not just the casual dress you might notice being different...

![Hair](http://i.imgur.com/sh4dE.jpg)

When my hair is six inches straight up, you know it's finally FRIDAY!  
]]></description><link>/post/friday</link><guid isPermaLink="true">/post/friday</guid><dc:creator><![CDATA[Jeff]]></dc:creator><pubDate>Fri, 09 Nov 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[Organizing client-side JavaScript with Browserify]]></title><description><![CDATA[![browserify](http://substack.net/doc/hujs/07_browserify.png)

How do you organize your client side js code?  
The node.js guys adopted the CommonJS approach - each function in it's own file  
and you simply require the file you want to use. here is a simple example:

saveUser.js 

    # this file contain one function that saves user info in our Database

    module.exports = function(userId) {
      // save user in DB
      console.log('user' + userId + ' saved in DB');
    };
   
app.js

    # require is the way to use a module in node.js. 
    # a module can be a bulit-in one or our own, similar to what we do here

    var foo = require('./saveUser.js');  # foo contains a function that can save our user
    foo(1);                              # calling our function with a user id

great for code reuse and easy to test, right? true, but how is that relevant to client-side js?  
I am glad you asked. I use a tool called [browserify](https://github.com/substack/node-browserify) that let me use CommonJS in the browser!  
let's jump right in and show you how to use it.
go ahead and create app.js and saveUser.js from the code samples above.  

now add a simple index.html that uses app.js

    <!DOCTYPE html>
    <html lang="en">
      <head>
      </head>

      <body>
        <p>CommonJS in the browser!</p>
       
         <script src="app.js"></script>
      </body>
    </html>

if you look at the browser's console you will notice an error: `Uncaught ReferenceError: require is not defined`   
that makes sense, since require is not available for js client side. let's fix that with browserify.

browserify is a node.js package so just like any other node package, you got to have [node.js](http://nodejs.org) on your machine and you should use npm to install it:

    npm install browserify -g

adding -g tells node to install this package globaly - it will available anywhere and not only in the current directory.

lets see what happend when we give it one argument, our js file:

    browserify app.js

we see a long javascript code printed in the console. browserify did it's magic and wrap our file so it will be able to use our require function.  
that's nice but we need to save the output into a file, right? lets do that with -o

    browserify app.js -o bundle.js

now we can use bundle.js insted of app.js in our html file:

    <!DOCTYPE html>
    <html lang="en">
      <head>
      </head>

      <body>
        <p>CommonJS in the browser!</p>

        <script src="bundle.js"></script>
      </body>
    </html>

if you see "user saved in DB" in the browser's console, everything is fine.

that's cool but I'm not going do this browserify dance every time I make a change to my js.  
right, that's why you can use -w to watch for changes and generate the bundle file:

    browserify app.js -o bundle.js -w

that's it, you can leave the spaghetti for the kitchen and enjoy mess-free js code.  

(All code samples for are available [here](https://github.com/oren/oren.github.com/tree/master/posts/browserify))
]]></description><link>/post/browserify</link><guid isPermaLink="true">/post/browserify</guid><dc:creator><![CDATA[Oren]]></dc:creator><pubDate>Mon, 05 Nov 2012 08:00:00 GMT</pubDate></item><item><title><![CDATA[That Weird Diet I Was On, a Summary]]></title><description><![CDATA[![Before](http://i.imgur.com/q8rWL.jpg)
![After](http://i.imgur.com/27Hjj.jpg)
(Same exact guy)

Over a fifteen-month period, I lost 139 pounds of fat and put on 13 pounds of lean muscle.  Hold your applause.  I did it _all wrong_.  I could've done it in ten months, but I'm lazy.  Some of the advice I'm going to give you, I periodically would ignore, myself.  I think you should stick to it, though.  This approach should really appeal to engineers and _especially_ testers, as we're metrics-driven people who enjoy combining tiny atomic behaviors to produce a significant result.

Here's a brief overview of what I did.

## Motivation
I'm a video gamer from way back.  I've always been a little fascinated with the high-jumping back-flipping pole-swinging heroes of that digital world.  I made a conscious decision that I wanted to do some of that stuff myself before I was too old or damaged for it to be a possiblity.  Enter [parkour](http://en.wikipedia.org/wiki/Parkour).  It's perfect for me, since I'm non-competitive and prone to bursts of enthusiastic jumping-on-stuff anyway.

## Ingredients
1x [The Four Hour Body](http://fourhourbody.com/), by Tim Ferriss
1x 45 lb. kettlebell
2x pair running shoes

### Micro Book Review
The Four Hour Body was written by the dude who wrote The Four Hour Workweek.  I'm a big [Lifehacker](http://www.lifehacker.com) fan, and they're big Tim Ferriss fans.  Some of the stuff in that book is crazy.  Some of it works.  In some cases, both are true.  I've tried a lot of it, but some of it I wouldn't try with YOUR body.

## The Slow-Carb Diet (The First 90%)

### Five simple rules:
1. Avoid "white" carbohydrates.
2. Eat the same few meals over and over again.
3. Don’t drink calories.
4. Don’t eat fruit.
5. Take one day off per week.

Eat four meals daily, spaced about once every four hours.  Drink more water than you think you need.  Get 8 hours of sleep per night.

There's a lot of science behind these little rules.  If you care, read the book or read the Internet.  I cared.  I did a whole heckuva lotta reading.  It probably helped to motivate me.  The big difference between slow-carb and the more common-sense caloric restriction diets is that slow-carb will not cannibalize an ounce of muscle.  Another big difference is that taking a "cheat day" prevents the depletion of willpower that causes most diets to fail.  Cheesecake is great, and you still get cheesecake.  You just don't get it until your weekly cheat day.  Then you're encouraged to eat the whole dang cheesecake yourself.

### Examples
Here's a typical day's eating for me:

- Breakfast
  - 3 whole eggs, fried in macadamia oil
  - Black beans from the can
  - Baby spinach in olive oil with salt & pepper
  - Vitamins B & D, Calcium, Magnesium, Potassium supplements
- 1st Lunch, 2nd Lunch, Dinner
  - Tri-tip steak
  - Black beans from the can
  - Steamed brocolli, steamed cauliflower

If I had nothing ready to eat, these were my most common meals from fast-food places:

**Chipotle:** Fajita bowl with black beans, steak, fajita veggies (no rice), mild salsa, guacamole, lettuce
**El Pollo Loco:**  Family meal deal w/ 8 pcs. mixed, no tortillas, pinto beans, and steamed veggies

## Aww man, Exercise?! (The Last 10%)
1. Two-arm Russian Kettlebell Swings
2. Turkish get-ups
3. Pushups
4. Pullups
5. Myotatic crunches
6. Running

I'm no physical trainer.  I can't tell you whether you should actually *do* any of these.  I know that these are the exercises I did, and I did rotating circuits with progressively-increasing loads.

For what it's worth, I lost about 80 lbs. before I started exercising _at all_.

In my case, I had two concerns:
1. The bigger they are, the harder they fall
2. Losses + gains simply resemble weaker losses.

If you've got a lot of fat to lose, diet alone will get you a huge part of the way.

## Protips
1. There will be a plateau about 6-8 weeks into the diet.  It'll pass.  Just don't change anything.
2. Eat your first meal within an hour of waking and go protein-heavy with it.
3. Snap pictures of every meal (including cheat days) and upload them to Tumblr or Instagram or whatever.  Blah blah science accountability blah.  It works.
4. Take before and after photos.  When the "Before" ceases to embarrass you, you know you're making progress.
5. Weigh yourself and measure the circumferences of each upper arm, each thigh, your chest, waist, and hips _daily_.  Those inches will show you that, even on days you're not losing _weight_, you're still reshaping your body in a meaningful way.
6. Hold off on buying new clothes until you absolutely can't go out in your old stuff anymore.  People won't notice you're skinnier until you buy new clothes.

## Conclusion
- This is a thing that works.
- It's not the _only_ thing that works.
- It appealed to me because it was made of little hacks that, when taken together, produce a huge result.
- Food is made of science.
- Bodies are made of science.
- My blood pressure is normal for the first time in my life.
- I don't secretly dread being photographed anymore.
- PARKOUR!

## Next Steps
Yellowpages.com Parkour Club?  **MAYBE!**
]]></description><link>/post/slow-carb-summary.html</link><guid isPermaLink="true">/post/slow-carb-summary.html</guid><dc:creator><![CDATA[Chris Dolan]]></dc:creator><pubDate>Fri, 02 Nov 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Halloween Madness]]></title><description><![CDATA[What a wacky fun Halloween this year at our Glendale office!  
Teams came together to provide spooky fun with creative themes like the Mad Hospital, the Witches Brew, the Hunger Games, and Milli Vanilli.  

Keep up the ghoul work!

![pic1](http://i.imgur.com/aJVal.jpg)
![pic2](http://i.imgur.com/hFXHJ.jpg)
![pic3](http://i.imgur.com/IECnG.jpg)
![pic4](http://i.imgur.com/KW8iK.jpg)
![pic5](http://i.imgur.com/2Pr7s.jpg)



]]></description><link>/post/halloween</link><guid isPermaLink="true">/post/halloween</guid><dc:creator><![CDATA[Faridi Hamedy]]></dc:creator><pubDate>Thu, 01 Nov 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Evaluating SolrMeter for Performance Testing]]></title><description><![CDATA[In this post I’m going to review SolrMeter, a performance measurement and testing tool for the popular Solr platform. Currently, there is a lack of such tools for systems using Solr. In case you are not familiar with Solr, it is best described as an enterprise search platform built on top of Apache Lucene.

Unlike most tools available for Web load testing and performance monitoring, SolrMeter includes both a loading component and a monitoring component in a single package. An integrated console in SolrMeter provides readouts for queries, updates, commits optimization and performance results on the same application screen as seen below.



![Operation Time Line in SolrMeter](http://i.imgur.com/FyjjL.png)
### Operation Time Line in SolrMeter

On this integrated console, you only need to provide a single parameter for Intended Queries per Minute to fire-off a performance test. All other parameters to run this test are available through Settings in the Edit menu. In the same way, we only need to input Intended Updates per Minute to kick-off a performance test on Updates. You can set additional parameters, HTTP Method Utilized, including through Advanced Settings menu in the Settings screen.
 
To specify query inputs to Query Console, we can use simple keywords, phrases or Boolean expressions along with filters and query faceting with the input query file. That aside, SolrMeter offers only limited support for an external parameter file. Only a few file formats for Update Console are acceptable and they must use (key,value) pairs to specify params.

SolrMeter displays performance test results on tabs for Histogram, Pie-charts, Query Time History and more. Along with Query Statistics, these charts provide a complete view of query performance. The cache history panel is pretty useful in tuning cache performance for queries. And, overall information for updates and queries is represented on Operation Time Line tab.

One minor inconvenience in all this is that unlike JMeter and openSTA, SolrMeter randomizes the number of queries generated per second while achieving the specified QPM target. This is easily alleviated by modifying software settings in Settings menu OR modifying SolrMeter source-code.

Overall, SolrMeter offers several features useful for performance tuning Solr instances. And, because SolrMeter is open-source, features can be added and existing features can be refined easily.

References:

* SolrMeter http://code.google.com/p/solrmeter/
* Solr http://lucene.apache.org/solr/
 
]]></description><link>/post/solrmeter_performance_testing_solr</link><guid isPermaLink="true">/post/solrmeter_performance_testing_solr</guid><dc:creator><![CDATA[Pradeep Teregowda]]></dc:creator><pubDate>Tue, 30 Oct 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Fun day in Long Beach]]></title><description><![CDATA[The Ad Delivery Team hasn’t had a team outing for a while.  
Movies and laser tag don’t satisfy us anymore.  We need to do something outdoor and fun.  
Thanks to Julia Baker and David Shin for organizing, kayaking at Long Beach definitely is one of the best team outing events we had.

![kayaks1](http://farm9.staticflickr.com/8052/8123088176_ab25c9a756_z.jpg)
![kayaks2](http://i.imgur.com/JvZ4v.jpg)
![kayaks3](http://i.imgur.com/Eamfw.jpg)
![kayaks4](http://i.imgur.com/C10ni.jpg)
![kayaks5](http://i.imgur.com/WgDfn.jpg)
![kayaks6](http://farm9.staticflickr.com/8187/8123137984_b79c1b0dfa.jpg)
![kayaks7](http://farm9.staticflickr.com/8472/8123137286_b2280212be.jpg)

Kayaks On The Water  
[5411 East Ocean Boulevard, Long Beach](http://goo.gl/maps/LlYRG)

Magic Lamp Lebanese Mediterranean Grill  
[5020 E Second St, Long Beach](http://goo.gl/maps/xA92Q)
]]></description><link>/post/kayaks</link><guid isPermaLink="true">/post/kayaks</guid><dc:creator><![CDATA[Lauren Yiu]]></dc:creator><pubDate>Thu, 25 Oct 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Benchmarking in Ruby]]></title><description><![CDATA[Benchmark (per [Dictionary.com](http://dictionary.reference.com/browse/benchmark)) - *"an established point of reference against which computers or programs can be measured in tests comparing their performance, reliability, etc."*

In my recent work with [caches](http://www.rubyops.net/caching), I've been making sure to benchmark my code before releasing it. It's pretty evident, that anyone working with caches cares about speed and for larger sites, every millisecond (and sometimes even microsecond) can count.

[Ruby] has built in benchmarking capibilities (see [the API for Benchmark](http://www.ruby-doc.org/stdlib-1.9.3/libdoc/benchmark/rdoc/Benchmark.html) for details beyond what I cover here). While Benchmark has several different methods of running benchmarks, I tend to focus on *Benchmark.bm*, which is a pretty straigh forward iteration through your code samples.

You can easily find good basic examples in the documentation, but I'll include them here for your convience.

### Basic Example

Benchmark Code:

    1: require 'benchmark'
    2: n = 50000
    3: Benchmark.bm do |x|
    4:   x.report { for i in 1..n; a = "1"; end }
    5:   x.report { n.times do   ; a = "1"; end }
    6:   x.report { 1.upto(n) do ; a = "1"; end }
    7: end


Which results in (depending on your machine specs):

        user     system      total        real
    1.033333   0.016667   1.016667 (  0.492106)
    1.483333   0.000000   1.483333 (  0.694605)
    1.516667   0.000000   1.516667 (  0.711077)


Great, so what's it all mean?

Well, if we look at the code sample line by line:

1. we require benchmark so it's availble for use
2. we set *n* to *50000* to defie the number of times to itterate the various loops were going to be benchmarking in this run
3. we open a *Benchmark.bm* block with *x*
4. define a report block, which contains your first loop -- a *for* loop
5. define your second loop -- *n.times*
6. define your thrid loop -- *upto(n)*
7. close your benchmark block

Simple enough -- we've started a benchmark block and defined thee things to benchmark.

Now for the results -- there's four columns of output here, "user" (or user CPU time), "system" (or system CPU time), "total" (or the sum of user and system CPU time) and "real" (or the actual real time elapsed).

So simply put, the conclusion of this test is that the *for* loop is going to be the fastest.

### Advanced Example

This is a simplified version of what I'm using for [Duality], [Mongocached] and [Diskcached]. All of which benchmark themselves against [Memcached] and in some cases eachother.


In this example, I'll be running a benchmark of [Diskcached], [Mongocached] and [Memcached] running a cache request, or *get('some_key')*.


Benchmark Code:

    require 'benchmark'
    require 'diskcached'
    require 'mongocached'
    require 'memcached'

    # init diskcached
    diskcache = Diskcached.new('/tmp/bm_cache')

    # init mongocached with defaults -- localhost
    mongocache = Mongocached.new()

    # init memcached
    memcache = Memcached.new("localhost:11211")

    # create a data object to be cached
    cache_content = "some string to be saved in cached"

    # set the number of times to itterate over the cache get
    #   I do this because these actions are very fast, so a
    #   single call, isn't really enough to show a difference.
    #
    #   For this, I typically use 100,000, as it allows you to
    #   easily translate all interations into a single
    #   intteration.
    #
    #   1 second for all, is 1 microsecond for a single iteration
    #   using "fuzzy logic".
    iterations = 100000

    # set each cache, so we have something to get
    diskcache.set("bm_key", cache_content)
    mongocache.set("bm_key", cache_content)
    memcache.set("bm_key", cache_content)

    # now for the meat
    Benchmark.bm do |bm|
      # first report - diskcached
      bm.report('disk') do
        (1..iterations).each do
          diskcache.get("bm_key")
        end
      end

      # second report - mongocached
      bm.report('mong') do
        (1..iterations).each do
          mongocache.get("bm_key")
        end
      end

      # third report - memcached
      bm.report('memc') do
        (1..iterations).each do
          memcache.get("bm_key")
        end
      end
    end


So what are we doing here?

* First we setup our caches to be benchmarked by initializing them and inserting some data to be fetched.
* Inside *Benchmark.bm* we create a report for each cache, and run *100000* cache fetches as fast as we can.

It's pretty much that simple.

It should be noted that this isn't a real emualtion of how this code will preform in production, but it should make it pretty clear which is faster and possible surface any gross inefficiencies.


Now, the results of this test for those that are curious (and to prove it all works):
> Note: this was run on a Debian virtual host with 8 cores.


          user       system    total       real
    disk  6.130000   2.180000   8.310000 (  8.501748)
    mong  29.650000  4.150000  33.800000 ( 49.266912)
    memc  2.330000   2.720000   5.050000 (  9.508415)


Okay, now what are our takeaway from this. [Mongocached] is quite a bit slower with reads, while [Diskcached] and [Memcached] are about the same.


### Closing

This is my little write up on how I benchmark. I would love comments and feedback from those who know more about it. I'm always down to learn.

Also, I have a template I use for benchmarking small samples of code in a gist -- I call it my [Benchmark A/B Test Suite](https://gist.github.com/3157875) -- enjoy!

> Note: This post was cross-posted from the [RubyOps.net blog entry by the same name](http://www.rubyops.net/benchmarking-in-ruby).


[Ruby]: http://www.rubyops.net/ruby
[Duality]: http://www.rubyops.net/duality-two-caches-at-once
[Mongocached]: http://www.rubyops.net/mongocached-simple-cache-using-mongodb
[Diskcached]: http://www.rubyops.net/diskcached-simple-disk-cacheing-for-ruby
[Memcached]: http://memcached.org/
]]></description><link>/post/benchmarking-in-ruby</link><guid isPermaLink="true">/post/benchmarking-in-ruby</guid><dc:creator><![CDATA[Josh]]></dc:creator><pubDate>Tue, 23 Oct 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Design is CRAP - Design principles for programmers]]></title><description><![CDATA[But I'm a programmer, you say, not a designer!  
Nope, tough cookies, design is part of the job.  

Let me tell you a story.  
I work at YP on the internal tools team.  We often have data requirements for new tools, but we never have design documents.  This means we have to build our own projects from scratch, and they never see design love from anyone but us.  This means that, for the first time for me, I've been really responsible for the look and feel of my projects.  Yikes!  Like many developers, I'm used to receiving a psd, or at minimum a wireframe before even starting on a project.  So I had to learn to design for the first time.

Scary, right?  However, as a programmer, you are the first line of defense.  
It's your responsibility as a programmer to make anything you touch as good as possible.  Every new feature, every tweak, and every bug you fix affects the user experience.  So why not make it as good as possible?

It's not too hard, really, just follow these four basic principles.

* Contrast
* Repetition
* Alignment
* Proximity

## Proximity
**Related elements should be grouped together**

Group elements that are meaningfully related.  Don't be afraid to use a lot of space to separate different groups! Let's see an example of terrible design:

![image](http://i.imgur.com/bCsmj.png)

Wow, that's bad!  Let's clean up the spacing using Proximity

![image](http://i.imgur.com/Hqk5C.png)

Now, isn't that better already?  
It doesn't take much to make a big difference!  Let's move on...

## Alignment
**Every item should have a visual connection to related items on the page**

Make a visual grid that connects every element to something related on the page.  In the same way as **Repetition**, use visual distinctions to indicate meaningful differences.

![image](http://i.imgur.com/OTFf7.png)

See how we use indents to separate headers from content?  Also note the use of a horizontal rule to give a visual anchor for the prices.

## Repetition
**Repeat some aspect of the design throughout the entire piece**

Repeat some aspect of the design throughout the entire piece.  Repeat some aspect of the design throughout the entire piece.  Repeat some...okay you get it, this one's pretty straightforward.

![image](http://i.imgur.com/OKi2j.png)

Coming along nicely!

## Contrast
**Emphasize the difference between different items**

This is basically the flip side of **Repetition**.  Use emphatically different styles for different types of information.  Don't be afraid to use small fonts, with proper use of spacing, alignment, and repetition, small fonts can be easy to read.  

Let's see what we can do with our example:

![image](http://i.imgur.com/3aYcW.png)

Here we use a fancy title font, we get rid of the awful all-caps, and we resize the less-important side text.

## Last touch

Here's a quick logo made from the font Mission Script from pay-what-you-want-site [losttype.com](http://losttype.com)

![image](http://i.imgur.com/372GE.png)


## What's next?  Steal!

Look at the web and see what you like, and then use a css/html inspection tool like chrome or firebug and steal it! Don't use frameworks, pre-rendered classes, or libraries.  Do it yourself, one line at a time.  That's the best way to learn.

### Resources

* Century Gothic font
* Mission Script font (from losttype.com)
* [Slides](http://www.slideshare.net/clemcke/design-is-crap) of my talk
* [Lost Type Co-op](http://losttype.com)
* [The League of Moveable Type](http://www.theleagueofmoveabletype.com)
* [Robin Williams: Design for Non-Designers](http://www.amazon.com/The-Non-Designers-Design-Book-Edition/dp/0321534042/)
* [Twitter Bootstrap](http://twitter.github.com/bootstrap/index.html)

]]></description><link>/post/design_is_crap</link><guid isPermaLink="true">/post/design_is_crap</guid><dc:creator><![CDATA[Chris Lemcke]]></dc:creator><pubDate>Mon, 22 Oct 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Building Object-Oriented jQuery Plugins]]></title><description><![CDATA[So you've been using [jQuery](http://jquery.com) as your Javascript framework and now you need to write a plugin. If you come from an Object-Oriented background like me, you may feel that jQuery's plugins leave a lot to be desired.

The basic formula to create a jQuery plugin is to extend the plugin namespace with a single method:


    #myplugin.js
    jQuery.fn.myplugin = function(){
      // Do some cool stuff here
    }

While that seems all fine and dandy for simple plugins, you may need to create more robust plugins that do many things, often in a non-linear fashion.

Some plugins get around this by adding tons of methods to jQuery's plugin namespace.


    $('#test').plugin();
    $('#test').pluginAdd('stuff');
    $('#test').pluginRemove('other stuff');
    $('#test').pluginDoSomethingCool();

I personally don't like that approach because it pollutes the jQuery plugin namespace with lots of methods --  it's best to stick to just one plugin method per plugin.

Other plugins use the first parameter of the plugin to call methods:

    $('#test').plugin();
    $('#test').plugin('add', 'stuff');
    $('#test').plugin('remove', 'other stuff');
    $('#test').plugin('doSomethingCool');

This approach is a little awkward, especially if the plugin accepts an `options` object the first time it is created. This approachs means you would have to either write a switch of all the methods you want to expose, or blindly accept any string as a method name.

To get around these hurdles, you can use this basic template for jQuery plugins that provides access to an Object-Oriented interface if needed while still maintaining jQuery's simplicity of a single method in the plugin namespace.

The first thing you need to do is wrap all your plugin code in an anonymous function. This will help keep things nice and tidy without creating global variables.

    #myplugin.js
    (function($){
      // Your plugin code goes here
    })(jQuery);

Next, create your plugin as a class, where the first parameter is a single DOM element.

    #myplugin.js
    (function($){
      var MyPlugin = function(element){
        var elem = $(element);
        var obj = this;

        // Public method
        this.publicMethod = function(){
          console.log('publicMethod() called!');
        };
      };
    })(jQuery);

To make your new object-oriented class available as a jQuery plugin, write a simple wrapper function in the plugin namespace:

    #myplugin.js
    (function($){
      var MyPlugin = function(element){
        var elem = $(element);
        var obj = this;

        // Public method
        this.publicMethod = function(){
          console.log('publicMethod() called!');
        };
      };

      $.fn.myplugin = function(){
        return this.each(function(){
          var myplugin = new MyPlugin(this);
        });
      };
    })(jQuery);

Now, when you call `$(selector).myplugin()`, the jQuery plugin will loop through the matched elements and instantiate an instance of `MyPlugin` for each one, passing the element as the first argument. And by returning `this`, you can ensure that your plugin is chainable (e.g. `$(selector).myplugin().show()`).

But now there's a problem of how to get the object `myplugin` once it's been created. For this, I usually store the object in the elements data. This provides easy access to the object while allowing you to prevent accidental double instantiation in the event that the plugin was called again on the same element.

    #myplugin.js
    (function($){
      var MyPlugin = function(element){
        var elem = $(element);
        var obj = this;

        // Public method
        this.publicMethod = function(){
          console.log('publicMethod() called!');
        };
      };

      $.fn.myplugin = function(){
        return this.each(function(){
          var element = $(this);

          // Return early if this element already has a plugin instance
          if (element.data('myplugin')) return;

          var myplugin = new MyPlugin(this);

          // Store plugin object in this element's data
          element.data('myplugin', myplugin);
        });
      };
    })(jQuery);

Now you have easy access to the object should you need to run methods on it.

    $('#test').myplugin();
    var myplugin = $('#test').data('myplugin');
    myplugin.publicMethod(); // prints "publicMethod() called!" to console

If you need to get fancy and add an options argument or other required arguments, just pass them from the jQuery plugin to your plugin's constructor:

    #myplugin.js
    (function($){
      var MyPlugin = function(element, options){
        var elem = $(element);
        var obj = this;

        // Merge options with defaults
        var settings = $.extend({
          param: 'defaultValue'
        }, options || {});

        // Public method
        this.publicMethod = function(){
          console.log('publicMethod() called!');
        };
      };

      $.fn.myplugin = function(options){
        return this.each(function(){
          var element = $(this);

          // Return early if this element already has a plugin instance
          if (element.data('myplugin')) return;

          // pass options to plugin constructor
          var myplugin = new MyPlugin(this, options);

          // Store plugin object in this element's data
          element.data('myplugin', myplugin);
        });
      };
    })(jQuery);

You may also want to expose some of your object's methods while keeping others private. To make a private method, create a local function within your object using the `var` keyword:

    #myplugin.js
    (function($){
      var MyPlugin = function(element, options){
        var elem = $(element);
        var obj = this;
        var settings = $.extend({
          param: 'defaultValue'
        }, options || {});

        // Public method - can be called from client code
        this.publicMethod = function(){
          console.log('public method called!');
        };

        // Private method - can only be called from within this object
        var privateMethod = function(){
          console.log('private method called!');
        };
      };

      $.fn.myplugin = function(options){
        return this.each(function(){
          var element = $(this);

          // Return early if this element already has a plugin instance
          if (element.data('myplugin')) return;

          // pass options to plugin constructor
          var myplugin = new MyPlugin(this, options);

          // Store plugin object in this element's data
          element.data('myplugin', myplugin);
        });
      };
    })(jQuery);

To see an example of a plugin written in this fashion, check out my [Tagger](http://www.virgentech.com/code/view/id/3) plugin.

> *Note: This post was cross-posted from the [VirgenTech.com blog entry by the same name](http://www.virgentech.com/blog/2009/10/building-object-oriented-jquery-plugin.html).*
]]></description><link>/post/jquery-oo-plugins</link><guid isPermaLink="true">/post/jquery-oo-plugins</guid><dc:creator><![CDATA[Hector]]></dc:creator><pubDate>Tue, 25 Sep 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Screen Cheatsheet]]></title><description><![CDATA[Here's my screen cheat sheet. It's simultaneous incredibly useful and ridiculous to configure.  
Actually reminds me of my other favorite tool with this syndrome: vim.

### Configuration

I like to bind C-o instead of C-a for screen commands.  
I feel that C-o is easier for my old hands to hit.

Here's the skinny on what goes inside that cryptic screenrc:  
Use C-o to issue commands to screen

    escape ^Oo
 
I also bind F5 and F6 to previous and next window:

F5 for previous window

    bindkey -k k5 prev

F6 for next window

    bindkey -k k6 next

### SSH

To be able to use ssh-agent within screen, you'll need this in your screenrc:

    setenv SSH_AUTH_SOCK $HOME/.ssh/screen_agent
    screen -t remote ssh-agent ssh-agent -a $SSH_AUTH_SOCK $SHELL

### Internal commands

    C-o "         Shows a list of sessions.
    C-o w         Shows name of session the lower left.
    C-o c         Creates a new session.
    C-o d         Detaches the current session.
    C-o A         Names the current session.
    C-o n         Cycle to next session.
    C-o p         Cycle to previous session.
    C-o F         Fit the session to the current terminal.
    C-o :quit     Quit all running sessions.
    C-o S         Open a new region in a session.
    C-o <TAB>     Enter a newly created region.
    C-o X         Close a region in screen.
    C-o ]         Enables copy mode for copying or scrolling; use PgUp, or PgDn, etc.
                  Press <ENTER> to mark text for copying.
                  Press <ENTER> again to copy the text.
                  Press C-o ] again to paste.

### External commands

    screen -ls    List sessions.
    screen -r     Reattach a session.
    screen -r foo Reattach to foo.
    screen -S foo Create a screen named foo.
 
**Conclusion**  
Clear as mud right?

]]></description><link>/post/screen</link><guid isPermaLink="true">/post/screen</guid><dc:creator><![CDATA[min]]></dc:creator><pubDate>Wed, 19 Sep 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Performance Testing with Httperf]]></title><description><![CDATA[### Introduction

> *"[Httperf](http://www.hpl.hp.com/research/linux/httperf/) -- a tool for measuring web server performance. It provides a flexible facility for generating various HTTP workloads and for measuring server performance. The focus of httperf is not on implementing one particular benchmark but on providing a robust, high-performance tool that facilitates the construction of both micro- and macro-level benchmarks. The three distinguishing characteristics of httperf are its robustness, which includes the ability to generate and sustain server overload, support for the HTTP/1.1 and SSL protocols, and its extensibility to new workload generators and performance measurements."*
>
> *Source: [Httperf Homepage](http://www.hpl.hp.com/research/linux/httperf/)*

##### Httperf's Default Scope
It's important to note that by default httperf only tests the standard http payload of your application -- e.g. the rendered HTML of the URL you are testing. Much like "curl", it does not load assets (images, javascript or css) by default. In this document, I will be referring to this as the "**base payload**". There are ways to configure it to load additional requests as part of the same session, which I will be covering. 


### Standard Usage
**Basic command-line usage:**

    $ httperf --server www.rubyops.net --port 80 --num-conns 10 --rate 1

**Results:**

    httperf --client=0/1 --server=www.rubyops.net --port=80 --uri=/ --rate=1 \ 
            --send-buffer=4096 --recv-buffer=16384 --num-conns=10 --num-calls=1

    Maximum connect burst length: 1

    Total: connections 10 requests 10 replies 10 test-duration 9.286 s

    Connection rate: 1.1 conn/s (928.6 ms/conn, <=1 concurrent connections)
    Connection time [ms]: min 284.2 avg 303.2 max 376.2 median 284.5 stddev 38.4
    Connection time [ms]: connect 91.8
    Connection length [replies/conn]: 1.000

    Request rate: 1.1 req/s (928.6 ms/req)
    Request size [B]: 68.0

    Reply rate [replies/s]: min 1.0 avg 1.0 max 1.0 stddev 0.0 (1 samples)
    Reply time [ms]: response 99.1 transfer 112.3
    Reply size [B]: header 241.0 content 29147.0 footer 0.0 (total 29388.0)
    Reply status: 1xx=0 2xx=10 3xx=0 4xx=0 5xx=0

    CPU time [s]: user 1.99 system 7.27 (user 21.5% system 78.3% total 99.7%)
    Net I/O: 31.0 KB/s (0.3*10^6 bps)

    Errors: total 0 client-timo 0 socket-timo 0 connrefused 0 connreset 0
    Errors: fd-unavail 0 addrunavail 0 ftab-full 0 other 0


In this example, I'm running ten connections _[\-\-num-conns 10]_ through [www.rubyops.net](http://www.rubyops.net/) _[\-\-server www.rubyops.net]_ at a rate of one connection per second _[\-\-rate 1]_. 

Breaking down the results, I typically focus on the following rows:

1. "Connection rate" -- this is mostly useful when not passing "--rate", which sends connections as fast as possible.
1. "Connection time [ms]" -- this is the meat of the test. It's a breakdown of various metrics related to the test against your base payload.
1. "Reply size" -- this is useful when testing change which are geared towards reducing the base payload of your application. Things like adding 'gzip' compression, uglifying JavaScript or 'haml', etc.
1. "Reply status" -- it's important to ensure that you're getting 200's when testing (or perhaps 302s if that's expected).

#### Being a Hog!

While my examples don't include this, using the "\-\-hog" flag when running httperf on a host dedicated to generating load is a very good idea. This tells httperf to use as many TCP connections as possible, thus avoiding bottlenecks. This flag should probably be omitted if generating load on the same box your application is running on.

### Testing Pages with AJAX

In more advanced usages you can create a a series of URIs to pass to emulate a single session. This is particularly useful when you're performance testing a page with several AJAX calls. 

To do this, you need to create a connections file with all URIs you want to hit.

**sessions.log**

    /
            /foo
            /bar
            /bah

You then need specify the log file you want to use in the place of "\-\-uri" to tell 'httperf' what paths to use.

    httperf --server www.rubyops.net --wsesslog 10,1,sessions.log


Obviously, I'm not implementing "/foo", "/bar" and "/bah" as AJAX on my site, but you get the idea. 

So what am I doing here? With "\-\-wsesslog", the first to field is the number of connections to make, basically the same as "\-\-num-conns" from the previous example. The second field is defined as "burst-to-burst user think time", which most simply means the number of times to access the URI before moving on to the next -- e.g. 1 would be one request per cycle through the list, 0.25 would be four requests per cycle through the list. 

Okay, simple enough. So what does 'httperf' do with that? Well instead of trying to explain it myself, I'm going quote  [httperf's man page](http://www.hpl.hp.com/research/linux/httperf/httperf-man.txt); *"When \-\-wsess or \-\-wsesslog is specified, httperf generates and measures sessions instead of individual calls and additional statistics are printed at the end of a test."*

### Replaying Production Logs

Httperf makes replaying production logs somewhat simple with the "\-\-wlog" option, which is used to generate a sequence of URIs to access. The one oddity, and why I say "somewhat simple" is that it expects an ASCII NUL separated [\0] file (as opposed to "new line" separated [\n], see examples below for details).

The first step is to generate your list. I use [Nginx](/tag/nginx), so that's what I'm going to focus on here. That said, this should be pretty adaptable to most web servers. Here's the command I use to generate a traffic log from Nginx's access.log:

    $ awk '{ print $7 }' /path/to/logs/access.log > urls.log

This assumes -- of course -- that your request path is in the seventh column.

In rare caces you need to clean up a leading or trailing quote like so:

    $ awk '{ print $7 }' /path/to/logs/access.log | sed 's/^\"//g' | \
      sed 's/\"$//g' > urls.log


So with that, we have a list of URIs from [www.rubyops.net](http://www.rubyops.net/), which we've called "urls.log". From this, we need to generate a file which is ASCII NUL separated which we'll call "wlog.log":

Start with urls.log.

     /
     /tag
     /tag/ruby
     /archive
     /2012
     /2012/07

Convert it to wlog.log -- replace line breaks with ASCII NUL characters.

        $ tr "\n" "\0" < urls.log > wlog.log

Now we can run our test.

        $ httperf --server www.rubyops.net --wlog Y,wlog.log
        
Note, the "Y" (or "N") switch is simply telling httperf to loop through the urls in your log file (or not).

### Best Practices

I don't claim to be an expert in this area (**AT ALL**), however, here a few things I've picked up in my travels, which has made my life easier in regards to performance testing best practices. They aren't always hard rules and I've broken all of them out of necessity at one point or another.

5. Don't performance test against production applications!
6. Don't performance test against production services!
7. Don't performance test against production databases!
7. **Don't performance test against production ANYTHING!**
4. If possible, try to performance test in an environment which is identical to production in every way -- same configuration, same network, same OS, same hardware (including CPU, RAM, etc.) -- to make your tests as accurate as possible.
1. Whenever possible, generate load (i.e. run httperf) on a separate machine from the host that the application is running on. This seems like a no-brainer, but you'd be surprised…
2. Use "\-\-hog" any time you're generating load from a separate host and your request rate is high. Eat up those TCP connections, don't be shy!
3. Generating load from an external connection can be good to test your overall network latency, but be sure your starting point connection can handle large amounts of traffic. For example, generating 100,000 connections at 100QPS from a Cable or DSL line probably isn't the best idea.
1. Oh and **don't performance test against production!**

> Note: This post was cross-posted from the [RubyOps.net blog entry by the same name](http://www.rubyops.net/performance-testing-with-httperf).

]]></description><link>/post/httperf</link><guid isPermaLink="true">/post/httperf</guid><dc:creator><![CDATA[Josh]]></dc:creator><pubDate>Tue, 18 Sep 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Ruby Meetup]]></title><description><![CDATA[![meetup](http://i.imgur.com/sAxiL.jpg)

On Thursday, October 11, 2012 we will be hosting the monthly Ruby meetup at our office in Glendale.  
Come hungry and enjoy great food and awesome hackers!

### Schedule

7:00 – 7:15 Open  
7:15 – 7:30 Introductions  
7:30 – 9:00 Presentations  
9:00 – 10:00 Open / Networking  


### Presentations

We need presentations for this meetup! Each meetup features 3-4 presentations of 30 minutes each, and should pertain to Ruby / Ruby on Rails, or be of general interest to the Ruby community. Please contact Alf Mikula if you are interested in presenting. Include a title, brief summary of your proposed presentation, and a brief bio about yourself. Please see past meetups for examples.

[Meetup website](http://www.meetup.com/laruby/events/82438922/)
]]></description><link>/post/ruby-meetup</link><guid isPermaLink="true">/post/ruby-meetup</guid><dc:creator><![CDATA[Alf]]></dc:creator><pubDate>Mon, 17 Sep 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Preview markdown files locally]]></title><description><![CDATA[I don't like to push my markdown files to github every time i make a change, just to realize 
I forgot a space or something tiny like that.. and my 'git log' is cluttered with 'readme' commits.    
enter [GFMS](https://github.com/ypocat/gfms) - Github Flavored Markdown Server.

it's a small node server that let's you preview your markdown files locally.

    npm install gfms -g
    cd <a folder with markdown files>
    gfms -p 1234
    http://localhost:1234/

just make a change to your md file and watch the rendered html on the browser. 
no need to hit refresh! (thanks to WebSocket)

[![gfms](http://i.imgur.com/uJxaM.png)](http://i.imgur.com/uJxaM.png)



]]></description><link>/post/markdown</link><guid isPermaLink="true">/post/markdown</guid><dc:creator><![CDATA[Oren]]></dc:creator><pubDate>Sat, 15 Sep 2012 07:00:00 GMT</pubDate></item><item><title><![CDATA[Upcoming node.js events]]></title><description><![CDATA[Just in case you find yourself in any of the locations below...  

Shanghai, Sep 14-16  
first node conference in China  
[http://www.hujs.org/](http://www.hujs.org/)  

Berlin, Oct 5  
hacking on drones - each team gets http://ardrone2.parrot.com/ and hack for a day!  
[http://nodecopter.com/](http://nodecopter.com/)

Dublin, Oct 18-19  
[http://www.nodedublin.com/](http://www.nodedublin.com/)

NY, Oct 22   
[http://empirejs.org/](http://empirejs.org/)

Portland, Oct 23-24  
keeping it realtime conference   
[http://krtconf.com](http://krtconf.com)

San Francisco, Nov 10-12  
48 hours of node hackathon. you can join remotely  
[http://nodeknockout.com/](http://nodeknockout.com/)

]]></description><link>/post/node-events</link><guid isPermaLink="true">/post/node-events</guid><dc:creator><![CDATA[Oren]]></dc:creator><pubDate>Thu, 13 Sep 2012 07:00:00 GMT</pubDate></item></channel></rss>